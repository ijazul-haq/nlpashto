# NLPashto â€“ NLP Toolkit for Pashto
![GitHub](https://img.shields.io/github/license/ijazul-haq/nlpashto) ![GitHub contributors](https://img.shields.io/github/contributors/ijazul-haq/nlpashto) ![code size](https://img.shields.io/github/languages/code-size/ijazul-haq/nlpashto)

NLPashto is a Python suite for Pashto Natural Language Processing, initiated at Shanghai Jiao Tong University. 

## Prerequisites
To use NLPashto you will need:
* Python 3.8+

## Installing NLPashto
NLPashto can be installed from PyPi using this command
```bash
pip install nlpashto
```

## Downloading Models
Call the download() function and pass the "model name" as argument.
```bash
nlpashto.download('space_correct')
```
Valid model names: 'space_correct', 'pos_tag', 'word_segment', 'pold', 'snd'

If the model name was not specified, all the available models will be downloaded


## Basic Usage


### Space Correction
Space correction module can be used to correct the space-omission and space-insertion errors. It will remove extra spaces from the text and will insert space where necessary. Itâ€™s a beta version and only recommended if the input text is extremely noisy. 

```python
from nlpashto import space_correct

noisy_text = 'Ù‡  Ù…  Ø¯  Ø§  Ø±  Ù†  Ú« Ù‡ Øª ÛŒ Ø± Ù‡ Ø´ Ù¾ Ù‡ Ø§ ÙˆÙˆØ±ÚÙ¾Ù‡Ù‡ÛŒÙˆØ§Ø¯Ú©ÛØ¯Ú©Ø±ÙˆÙ†Ø§ÙˆÛŒØ±ÙˆØ³Ù„Ù‡Ø§Ù…Ù„Ù‡ÛµØªÙ†Ù‡Ù…Ú“Ù‡Ø´ÙˆÙŠ'
corrected = space_correct(noisy_text)
print(corrected)
Output:: Ù‡Ù…Ø¯Ø§Ø±Ù†Ú«Ù‡ ØªÛŒØ±Ù‡ Ø´Ù¾Ù‡ Ø§Ùˆ ÙˆØ±Ú Ù¾Ù‡ Ù‡ÛŒÙˆØ§Ø¯ Ú©Û Ø¯ Ú©Ø±ÙˆÙ†Ø§ ÙˆÛŒØ±ÙˆØ³ Ù„Ù‡ Ø§Ù…Ù„Ù‡ Ûµ ØªÙ†Ù‡ Ù…Ú“Ù‡ Ø´ÙˆÙŠ
```


### Word Segmentatoin
```python
from nlpashto import word_segment

text = 'Ù‡Ù…Ø¯Ø§Ø±Ù†Ú«Ù‡ ØªÛŒØ±Ù‡ Ø´Ù¾Ù‡ Ø§Ùˆ ÙˆØ±Ú Ù¾Ù‡ Ù‡ÛŒÙˆØ§Ø¯ Ú©Û Ø¯ Ú©Ø±ÙˆÙ†Ø§ ÙˆÛŒØ±ÙˆØ³ Ù„Ù‡ Ø§Ù…Ù„Ù‡ Ûµ ØªÙ†Ù‡ Ù…Ú“Ù‡ Ø´ÙˆÙŠ'
segmented_text = word_segment(text)
print(segmented_text)

Output:: ['Ù‡Ù…Ø¯Ø§Ø±Ù†Ú«Ù‡', 'ØªÛŒØ±Ù‡', 'Ø´Ù¾Ù‡', 'Ø§Ùˆ', 'ÙˆØ±Ú', 'Ù¾Ù‡', 'Ù‡ÛŒÙˆØ§Ø¯', 'Ú©Û', 'Ø¯', 'Ú©Ø±ÙˆÙ†Ø§ ÙˆÛŒØ±ÙˆØ³', 'Ù„Ù‡ Ø§Ù…Ù„Ù‡', 'Ûµ', 'ØªÙ†Ù‡', 'Ù…Ú“Ù‡', 'Ø´ÙˆÙŠ']
```

### Part-of-speech (POS) Tagging
For further detail about the POS tagger and the corpus used for training please have a look at our paper [The Pashto Corpus and Machine Learning Model for Automatic POS Tagging](https://www.researchsquare.com/article/rs-2712906/v1)
```python
from nlpashto import pos_tag

text = 'Ù‡Ù…Ø¯Ø§Ø±Ù†Ú«Ù‡ ØªÛŒØ±Ù‡ Ø´Ù¾Ù‡ Ø§Ùˆ ÙˆØ±Ú Ù¾Ù‡ Ù‡ÛŒÙˆØ§Ø¯ Ú©Û Ø¯ Ú©Ø±ÙˆÙ†Ø§ ÙˆÛŒØ±ÙˆØ³ Ù„Ù‡ Ø§Ù…Ù„Ù‡ Ûµ ØªÙ†Ù‡ Ù…Ú“Ù‡ Ø´ÙˆÙŠ'
segmented_text = word_segment(text)
tagged = pos_tag(segmented_text)
print(tagged) 

Output:: [['Ù‡Ù…Ø¯Ø§Ø±Ù†Ú«Ù‡', 'RB'], ['ØªÛŒØ±Ù‡', 'JJ'], ['Ø´Ù¾Ù‡', 'NNF'], ['Ø§Ùˆ', 'CC'], ['ÙˆØ±Ú', 'NNM'], ['Ù¾Ù‡', 'IN'], ['Ù‡ÛŒÙˆØ§Ø¯', 'NNM'], ['Ú©Û', 'PT'], ['Ø¯', 'IN'], ['Ú©Ø±ÙˆÙ†Ø§ ÙˆÛŒØ±ÙˆØ³', 'NNP'], ['Ù„Ù‡ Ø§Ù…Ù„Ù‡', 'RB'], ['Ûµ', 'NB'], ['ØªÙ†Ù‡', 'NNS'], ['Ù…Ú“Ù‡', 'JJ'], ['Ø´ÙˆÙŠ', 'VBDX']]
```

### Offensive Language Detection
A fine-tuned BERT model for toxicity detection in Pashto text

```python
from nlpashto import pold

offensive_text = 'Ù…Ú“Ù‡ ÛŒÙˆ Ú©Ø³ ÙˆÛŒ ØµØ±Ù ÚØ§Ù† Ø´Ø±Ù…ÙˆÛŒ Ø§Ùˆ ÛŒÙˆ Ø³ØªØ§ ØºÙˆÙ†Ø¯Û’ Ø¬Ø§Ù‡Ù„ ÙˆÛŒ Ú†Û Ù‚ÙˆÙ… Ø§Ùˆ Ù…Ù„Øª Ø´Ø±Ù…ÙˆÛŒ'
pold(text)

Output:: 1


normal_text = 'ØªØ§Ø³Ùˆ Ø±ÚšØªÛŒØ§ ÙˆØ§ÛŒØ¦ Ø®ÙˆØ± ğŸ™'
pold(text)

Output:: 0
```

### Spammy Names Detection
A Naive Bayes classifier model that will predict whether the string of characters is a valid name or not. It can be used to identify spammy profile names on social media.

```python
from nlpashto import snd

not_a_name = 'Ù…Ø³Ø§ÙØ± Ù„Ø§Ù„ÛŒ'
snd(not_a_name)

Output:: 0.2


valid_name = 'Ø´Ø§Ù‡Ø¯ Ø§ÙØ±ÙŠØ¯ÛŒ'
snd(text)

Output:: 1.0
```
